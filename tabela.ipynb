{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qPfgJg0FmYRE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MyCtDLp2mYRJ"
      },
      "outputs": [],
      "source": [
        "class LLMComparator:\n",
        "    def __init__(self):\n",
        "        # Dados das tr√™s fontes diferentes\n",
        "        self.data_sources = {\n",
        "            'DeepSeek Source': {\n",
        "                'ChatGPT (GPT-4)': {\n",
        "                    'Overall Score': 85,\n",
        "                    'IFEval': 85,\n",
        "                    'BBH': 87,\n",
        "                    'MATH': 70,\n",
        "                    'GPQA': 80,\n",
        "                    'MuSR': 80,\n",
        "                    'MMLU-Pro': 85,\n",
        "                    'CO2_Emissions': 4.3  # g por consulta\n",
        "                },\n",
        "                'DeepSeek-V2': {\n",
        "                    'Overall Score': 78,\n",
        "                    'IFEval': 80,\n",
        "                    'BBH': 80,\n",
        "                    'MATH': 75,\n",
        "                    'GPQA': 70,\n",
        "                    'MuSR': 75,\n",
        "                    'MMLU-Pro': None,  # N√£o divulgado\n",
        "                    'CO2_Emissions': 1.8  # g por consulta\n",
        "                }\n",
        "            },\n",
        "            'ChatGPT Source': {\n",
        "                'ChatGPT (GPT-4)': {\n",
        "                    'Overall Score': 85,\n",
        "                    'IFEval': 90,\n",
        "                    'BBH': 87,\n",
        "                    'MATH': 80,\n",
        "                    'GPQA': 88,\n",
        "                    'MuSR': 86,\n",
        "                    'MMLU-Pro': 92,\n",
        "                    'CO2_Emissions': 450  # g por resposta (0.45kg)\n",
        "                },\n",
        "                'DeepSeek-V2': {\n",
        "                    'Overall Score': 80,\n",
        "                    'IFEval': 80,\n",
        "                    'BBH': 82,\n",
        "                    'MATH': 75,\n",
        "                    'GPQA': 85,\n",
        "                    'MuSR': 78,\n",
        "                    'MMLU-Pro': 85,\n",
        "                    'CO2_Emissions': 600  # g por resposta (0.60kg)\n",
        "                }\n",
        "            },\n",
        "            'Gemini Source': {\n",
        "                'ChatGPT (GPT-4)': {\n",
        "                    'Overall Score': 90,\n",
        "                    'IFEval': 90,\n",
        "                    'BBH': 85,\n",
        "                    'MATH': 60,\n",
        "                    'GPQA': 60,\n",
        "                    'MuSR': 85,\n",
        "                    'MMLU-Pro': 90,\n",
        "                    'CO2_Emissions': None  # N√£o divulgado\n",
        "                },\n",
        "                'DeepSeek-V2': {\n",
        "                    'Overall Score': 80,\n",
        "                    'IFEval': 85,\n",
        "                    'BBH': 75,\n",
        "                    'MATH': 50,\n",
        "                    'GPQA': 50,\n",
        "                    'MuSR': 80,\n",
        "                    'MMLU-Pro': 80,\n",
        "                    'CO2_Emissions': None  # N√£o divulgado\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.current_source = 'DeepSeek Source'\n",
        "        self.criteria = [\n",
        "            'Overall Score', 'IFEval', 'BBH', 'MATH',\n",
        "            'GPQA', 'MuSR', 'MMLU-Pro'\n",
        "        ]\n",
        "\n",
        "    def set_data_source(self, source_name):\n",
        "        \"\"\"Define a fonte de dados atual\"\"\"\n",
        "        if source_name in self.data_sources:\n",
        "            self.current_source = source_name\n",
        "            print(f\"‚úÖ Fonte alterada para: {source_name}\")\n",
        "        else:\n",
        "            print(\"‚ùå Fonte n√£o encontrada. Fontes dispon√≠veis: DeepSeek Source, ChatGPT Source, Gemini Source\")\n",
        "\n",
        "    def get_current_models(self):\n",
        "        \"\"\"Retorna os modelos da fonte atual\"\"\"\n",
        "        return self.data_sources[self.current_source]\n",
        "\n",
        "    def display_comparison_table(self):\n",
        "        \"\"\"Exibe tabela comparativa formatada da fonte atual\"\"\"\n",
        "        models = self.get_current_models()\n",
        "        table_data = []\n",
        "        headers = ['Crit√©rio', 'ChatGPT (GPT-4)', 'DeepSeek-V2', 'Diferen√ßa']\n",
        "\n",
        "        for criterion in self.criteria:\n",
        "            chatgpt_score = models['ChatGPT (GPT-4)'][criterion]\n",
        "            deepseek_score = models['DeepSeek-V2'][criterion]\n",
        "\n",
        "            if chatgpt_score is None or deepseek_score is None:\n",
        "                chatgpt_display = \"N/D\" if chatgpt_score is None else f\"{chatgpt_score}%\"\n",
        "                deepseek_display = \"N/D\" if deepseek_score is None else f\"{deepseek_score}%\"\n",
        "                difference_display = \"N/D\"\n",
        "            else:\n",
        "                chatgpt_display = f\"{chatgpt_score}%\"\n",
        "                deepseek_display = f\"{deepseek_score}%\"\n",
        "                difference = chatgpt_score - deepseek_score\n",
        "                difference_display = f\"{difference:+.1f}%\"\n",
        "\n",
        "            table_data.append([\n",
        "                criterion,\n",
        "                chatgpt_display,\n",
        "                deepseek_display,\n",
        "                difference_display\n",
        "            ])\n",
        "\n",
        "        # Adiciona emiss√µes de CO2\n",
        "        chatgpt_co2 = models['ChatGPT (GPT-4)']['CO2_Emissions']\n",
        "        deepseek_co2 = models['DeepSeek-V2']['CO2_Emissions']\n",
        "\n",
        "        if chatgpt_co2 is None or deepseek_co2 is None:\n",
        "            co2_difference = \"N/D\"\n",
        "            co2_reduction = \"N/D\"\n",
        "        else:\n",
        "            # Converter para a mesma unidade (gramas) para compara√ß√£o\n",
        "            chatgpt_g = chatgpt_co2 if chatgpt_co2 < 100 else chatgpt_co2  # j√° est√° em gramas ou precisa converter?\n",
        "            deepseek_g = deepseek_co2 if deepseek_co2 < 100 else deepseek_co2\n",
        "\n",
        "            if self.current_source == 'ChatGPT Source':\n",
        "                # Nesta fonte, os valores est√£o em g por resposta (450g, 600g)\n",
        "                co2_difference = f\"{deepseek_g - chatgpt_g:+.1f}g\"\n",
        "                co2_reduction = f\"{(chatgpt_g - deepseek_g) / chatgpt_g * 100:.1f}%\"\n",
        "            else:\n",
        "                # DeepSeek Source: valores em g por consulta\n",
        "                co2_difference = f\"{deepseek_g - chatgpt_g:+.1f}g\"\n",
        "                co2_reduction = f\"{(chatgpt_g - deepseek_g) / chatgpt_g * 100:.1f}%\"\n",
        "\n",
        "        co2_unit = \"g/consulta\" if self.current_source == 'DeepSeek Source' else \"g/resposta\"\n",
        "\n",
        "        table_data.append([\n",
        "            f'CO2 Emissions ({co2_unit})',\n",
        "            f\"{chatgpt_co2 if chatgpt_co2 else 'N/D'}\",\n",
        "            f\"{deepseek_co2 if deepseek_co2 else 'N/D'}\",\n",
        "            co2_reduction if co2_reduction != \"N/D\" else \"N/D\"\n",
        "        ])\n",
        "\n",
        "        print(f\"üîç COMPARA√á√ÉO: {self.current_source}\")\n",
        "        print(\"=\" * 70)\n",
        "        print(tabulate(table_data, headers=headers, tablefmt='grid'))\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "    def display_all_sources_comparison(self):\n",
        "        \"\"\"Exibe compara√ß√£o entre todas as fontes de dados\"\"\"\n",
        "        print(\"üìä COMPARA√á√ÉO ENTRE TODAS AS FONTES DE DADOS\")\n",
        "        print(\"=\" * 90)\n",
        "\n",
        "        all_data = []\n",
        "        headers = ['Crit√©rio', 'DeepSeek Source', 'ChatGPT Source', 'Gemini Source', 'Varia√ß√£o Max']\n",
        "\n",
        "        for criterion in self.criteria + ['CO2_Emissions']:\n",
        "            row = [criterion]\n",
        "            values = []\n",
        "\n",
        "            for source_name in ['DeepSeek Source', 'ChatGPT Source', 'Gemini Source']:\n",
        "                models = self.data_sources[source_name]\n",
        "                chatgpt_val = models['ChatGPT (GPT-4)'][criterion]\n",
        "                deepseek_val = models['DeepSeek-V2'][criterion]\n",
        "\n",
        "                if criterion == 'CO2_Emissions':\n",
        "                    if chatgpt_val is None or deepseek_val is None:\n",
        "                        display_val = \"ChatGPT: N/D\\nDeepSeek: N/D\"\n",
        "                    else:\n",
        "                        unit = \"g/consulta\" if source_name == 'DeepSeek Source' else \"g/resposta\"\n",
        "                        display_val = f\"ChatGPT: {chatgpt_val}{unit}\\nDeepSeek: {deepseek_val}{unit}\"\n",
        "                else:\n",
        "                    if chatgpt_val is None or deepseek_val is None:\n",
        "                        display_val = \"ChatGPT: N/D\\nDeepSeek: N/D\"\n",
        "                    else:\n",
        "                        display_val = f\"ChatGPT: {chatgpt_val}%\\nDeepSeek: {deepseek_val}%\"\n",
        "\n",
        "                row.append(display_val)\n",
        "                # Modified condition to ensure both values are not None before adding to 'values' for comparison\n",
        "                if chatgpt_val is not None and deepseek_val is not None and criterion != 'CO2_Emissions':\n",
        "                    values.extend([chatgpt_val, deepseek_val])\n",
        "\n",
        "            # Calcular varia√ß√£o m√°xima\n",
        "            if values and criterion != 'CO2_Emissions':\n",
        "                variation = max(values) - min(values)\n",
        "                row.append(f\"{variation:.1f}%\")\n",
        "            else:\n",
        "                row.append(\"N/D\")\n",
        "\n",
        "            all_data.append(row)\n",
        "\n",
        "        print(tabulate(all_data, headers=headers, tablefmt='grid'))\n",
        "        print(\"\\n\" + \"=\" * 90)\n",
        "\n",
        "    def create_radar_chart(self):\n",
        "        \"\"\"Cria gr√°fico radar para compara√ß√£o visual da fonte atual\"\"\"\n",
        "        models = self.get_current_models()\n",
        "        # Use criteria excluding 'MMLU-Pro' as the base for the radar chart\n",
        "        criteria_base = self.criteria[:-1]\n",
        "\n",
        "        # Filter criteria where BOTH models have non-None data\n",
        "        criteria_to_plot = []\n",
        "        chatgpt_scores_filtered = []\n",
        "        deepseek_scores_filtered = []\n",
        "\n",
        "        for c in criteria_base:\n",
        "            chatgpt_val = models['ChatGPT (GPT-4)'][c]\n",
        "            deepseek_val = models['DeepSeek-V2'][c]\n",
        "            if chatgpt_val is not None and deepseek_val is not None:\n",
        "                criteria_to_plot.append(c)\n",
        "                chatgpt_scores_filtered.append(chatgpt_val)\n",
        "                deepseek_scores_filtered.append(deepseek_val)\n",
        "\n",
        "        if not criteria_to_plot:\n",
        "            print(\"‚ùå Dados insuficientes para criar o gr√°fico radar\")\n",
        "            return\n",
        "\n",
        "        # Prepare angles and data for radar plot (closing the loop)\n",
        "        num_criteria = len(criteria_to_plot)\n",
        "        # Generate angles for N criteria, ending before 2*pi\n",
        "        angles = np.linspace(0, 2*np.pi, num_criteria, endpoint=False).tolist()\n",
        "\n",
        "        # Add the first point to the end of angles and scores to close the circular plot\n",
        "        angles_closed = angles + [angles[0]]\n",
        "        chatgpt_scores_closed = chatgpt_scores_filtered + [chatgpt_scores_filtered[0]]\n",
        "        deepseek_scores_closed = deepseek_scores_filtered + [deepseek_scores_filtered[0]]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "        # Plot using the closed lists\n",
        "        ax.plot(angles_closed, chatgpt_scores_closed, 'o-', linewidth=2, label='ChatGPT (GPT-4)', color='#10a37f')\n",
        "        ax.fill(angles_closed, chatgpt_scores_closed, alpha=0.25, color='#10a37f')\n",
        "\n",
        "        ax.plot(angles_closed, deepseek_scores_closed, 'o-', linewidth=2, label='DeepSeek-V2', color='#ff6b35')\n",
        "        ax.fill(angles_closed, deepseek_scores_closed, alpha=0.25, color='#ff6b35')\n",
        "\n",
        "        # Use original angles and criteria for thetagrids\n",
        "        ax.set_thetagrids(np.degrees(angles), criteria_to_plot)\n",
        "        ax.set_ylim(0, 100)\n",
        "        ax.set_yticks([20, 40, 60, 80, 100])\n",
        "        ax.grid(True)\n",
        "\n",
        "        plt.title(f'Compara√ß√£o de Desempenho: {self.current_source}\\n', size=14, fontweight='bold')\n",
        "        plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def create_bar_chart(self):\n",
        "        \"\"\"Cria gr√°fico de barras para compara√ß√£o lado a lado da fonte atual\"\"\"\n",
        "        models = self.get_current_models()\n",
        "        criteria = [c for c in self.criteria[:-1] if models['ChatGPT (GPT-4)'][c] is not None and models['DeepSeek-V2'][c] is not None]\n",
        "\n",
        "        if not criteria:\n",
        "            print(\"‚ùå Dados insuficientes para criar o gr√°fico de barras\")\n",
        "            return\n",
        "\n",
        "        chatgpt_scores = [models['ChatGPT (GPT-4)'][c] for c in criteria]\n",
        "        deepseek_scores = [models['DeepSeek-V2'][c] for c in criteria]\n",
        "\n",
        "        x = np.arange(len(criteria))\n",
        "        width = 0.35\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "        bars1 = ax.bar(x - width/2, chatgpt_scores, width, label='ChatGPT (GPT-4)', color='#10a37f', alpha=0.8)\n",
        "        bars2 = ax.bar(x + width/2, deepseek_scores, width, label='DeepSeek-V2', color='#ff6b35', alpha=0.8)\n",
        "\n",
        "        ax.set_xlabel('Crit√©rios de Avalia√ß√£o')\n",
        "        ax.set_ylabel('Pontua√ß√£o (%)')\n",
        "        ax.set_title(f'Compara√ß√£o Detalhada por Crit√©rio - {self.current_source}')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(criteria, rotation=45, ha='right')\n",
        "        ax.legend()\n",
        "        ax.set_ylim(0, 100)\n",
        "\n",
        "        # Adicionar valores nas barras\n",
        "        for bar in bars1:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f'{height}%',\n",
        "                       xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                       xytext=(0, 3),\n",
        "                       textcoords=\"offset points\",\n",
        "                       ha='center', va='bottom')\n",
        "\n",
        "        for bar in bars2:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f'{height}%',\n",
        "                       xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                       xytext=(0, 3),\n",
        "                       textcoords=\"offset points\",\n",
        "                       ha='center', va='bottom')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def environmental_impact_comparison(self):\n",
        "        \"\"\"Mostra compara√ß√£o de impacto ambiental da fonte atual\"\"\"\n",
        "        models = self.get_current_models()\n",
        "        chatgpt_co2 = models['ChatGPT (GPT-4)']['CO2_Emissions']\n",
        "        deepseek_co2 = models['DeepSeek-V2']['CO2_Emissions']\n",
        "\n",
        "        if chatgpt_co2 is None or deepseek_co2 is None:\n",
        "            print(\"üå± DADOS DE EMISS√ïES N√ÉO DISPON√çVEIS PARA ESTA FONTE\")\n",
        "            return\n",
        "\n",
        "        unit = \"g por consulta\" if self.current_source == 'DeepSeek Source' else \"g por resposta\"\n",
        "\n",
        "        reduction = ((chatgpt_co2 - deepseek_co2) / chatgpt_co2) * 100\n",
        "        efficiency_ratio = chatgpt_co2 / deepseek_co2\n",
        "\n",
        "        print(\"üå± AN√ÅLISE DE IMPACTO AMBIENTAL\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"ChatGPT (GPT-4): {chatgpt_co2}{unit}\")\n",
        "        print(f\"DeepSeek-V2: {deepseek_co2}{unit}\")\n",
        "        print(f\"Redu√ß√£o: {reduction:.1f}% menos emiss√µes\")\n",
        "        print(f\"Efici√™ncia: DeepSeek √© {efficiency_ratio:.1f}x mais eficiente\")\n",
        "        print(\"\\nüí° Interpreta√ß√£o:\")\n",
        "        print(\"- DeepSeek emite aproximadamente 58% menos CO‚ÇÇ que ChatGPT\")\n",
        "        print(\"- Arquitetura Mixture of Experts (MoE) √© mais sustent√°vel\")\n",
        "        print(\"- Impacto significativo quando escalado para milh√µes de usu√°rios\")\n",
        "\n",
        "    def recommendation_engine(self, user_priority):\n",
        "        \"\"\"\n",
        "        Sistema de recomenda√ß√£o baseado na prioridade do usu√°rio\n",
        "        Considera dados consolidados de todas as fontes\n",
        "        \"\"\"\n",
        "        # Calcular m√©dias de todas as fontes dispon√≠veis\n",
        "        chatgpt_scores = []\n",
        "        deepseek_scores = []\n",
        "\n",
        "        for source_name, models in self.data_sources.items():\n",
        "            for criterion in self.criteria:\n",
        "                chatgpt_val = models['ChatGPT (GPT-4)'][criterion]\n",
        "                deepseek_val = models['DeepSeek-V2'][criterion]\n",
        "\n",
        "                if chatgpt_val is not None:\n",
        "                    chatgpt_scores.append(chatgpt_val)\n",
        "                if deepseek_val is not None:\n",
        "                    deepseek_scores.append(deepseek_val)\n",
        "\n",
        "        avg_chatgpt = np.mean(chatgpt_scores) if chatgpt_scores else 0\n",
        "        avg_deepseek = np.mean(deepseek_scores) if deepseek_scores else 0\n",
        "\n",
        "        # Updated priorities based on user request\n",
        "        priorities = {\n",
        "            'logica': ['DeepSeek-V2', 'Superior em tarefas matem√°ticas e l√≥gicas'],\n",
        "            'texto': ['ChatGPT (GPT-4)', 'Melhor para gera√ß√£o e compreens√£o de texto']\n",
        "        }\n",
        "\n",
        "        if user_priority in priorities:\n",
        "            recommendation, reason = priorities[user_priority]\n",
        "            print(f\"\\nüéØ RECOMENDA√á√ÉO PARA PRIORIDADE: {user_priority.upper()}\")\n",
        "            print(\"=\" * 60)\n",
        "            print(f\"Modelo Recomendado: {recommendation}\")\n",
        "            print(f\"Motivo: {reason}\")\n",
        "\n",
        "            if user_priority == 'logica':\n",
        "                print(f\"\\nüìä Performance M√©dia: DeepSeek {avg_deepseek:.1f}% vs ChatGPT {avg_chatgpt:.1f}%\")\n",
        "                print(\"‚úÖ Vantagem: Sustent√°vel e econ√¥mico, com desempenho competitivo\")\n",
        "            elif user_priority == 'texto':\n",
        "                print(f\"\\nüìä Performance M√©dia: ChatGPT {avg_chatgpt:.1f}% vs DeepSeek {avg_deepseek:.1f}%\")\n",
        "                print(\"‚úÖ Vantagem: Flu√™ncia textual superior e coer√™ncia contextual\")\n",
        "        else:\n",
        "            print(\"Prioridade n√£o reconhecida. Use: logica, texto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "26s-A5zEmYRN"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    comparator = LLMComparator()\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"ü§ñ COMPARADOR AVAN√áADO DE LLMs: M√∫ltiplas Fontes de Dados\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"1. üìä Ver Tabela Comparativa (Fonte Atual)\")\n",
        "        print(\"2. üåê Compara√ß√£o entre Todas as Fontes\")\n",
        "        print(\"3. üìä Gr√°fico de Barras\")\n",
        "        print(\"4. üå± An√°lise de Impacto Ambiental\")\n",
        "        print(\"5. üí° Sistema de Recomenda√ß√£o\")\n",
        "        print(\"6. üö™ Sair\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Fonte atual: {comparator.current_source}\")\n",
        "\n",
        "        choice = input(\"\\nEscolha uma op√ß√£o (1-6): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            comparator.display_comparison_table()\n",
        "        elif choice == '2':\n",
        "            comparator.display_all_sources_comparison()\n",
        "        elif choice == '3':\n",
        "            comparator.create_bar_chart()\n",
        "        elif choice == '4':\n",
        "            comparator.environmental_impact_comparison()\n",
        "        elif choice == '5':\n",
        "            print(\"\\nPrioridades dispon√≠veis: logica, texto\")\n",
        "            priority = input(\"Digite sua prioridade principal: \").strip().lower()\n",
        "            comparator.recommendation_engine(priority)\n",
        "        elif choice == '6':\n",
        "            print(\"Obrigado por usar o comparador avan√ßado! üëã\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"‚ùå Op√ß√£o inv√°lida! Tente novamente.\")\n",
        "\n",
        "        input(\"\\nPressione Enter para continuar...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoD5TqmJmYRO",
        "outputId": "b6ae9d42-6207-4dd8-a3e4-3923c29ea25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ü§ñ COMPARADOR AVAN√áADO DE LLMs: M√∫ltiplas Fontes de Dados\n",
            "======================================================================\n",
            "1. üìä Ver Tabela Comparativa (Fonte Atual)\n",
            "2. üåê Compara√ß√£o entre Todas as Fontes\n",
            "3. üìä Gr√°fico de Barras\n",
            "4. üå± An√°lise de Impacto Ambiental\n",
            "5. üí° Sistema de Recomenda√ß√£o\n",
            "6. üö™ Sair\n",
            "======================================================================\n",
            "Fonte atual: DeepSeek Source\n",
            "\n",
            "Escolha uma op√ß√£o (1-6): 2\n",
            "üìä COMPARA√á√ÉO ENTRE TODAS AS FONTES DE DADOS\n",
            "==========================================================================================\n",
            "+---------------+-------------------------+-------------------------+-----------------+----------------+\n",
            "| Crit√©rio      | DeepSeek Source         | ChatGPT Source          | Gemini Source   | Varia√ß√£o Max   |\n",
            "+===============+=========================+=========================+=================+================+\n",
            "| Overall Score | ChatGPT: 85%            | ChatGPT: 85%            | ChatGPT: 90%    | 12.0%          |\n",
            "|               | DeepSeek: 78%           | DeepSeek: 80%           | DeepSeek: 80%   |                |\n",
            "+---------------+-------------------------+-------------------------+-----------------+----------------+\n",
            "| IFEval        | ChatGPT: 85%            | ChatGPT: 90%            | ChatGPT: 90%    | 10.0%          |\n",
            "|               | DeepSeek: 80%           | DeepSeek: 80%           | DeepSeek: 85%   |                |\n",
            "+---------------+-------------------------+-------------------------+-----------------+----------------+\n",
            "| BBH           | ChatGPT: 87%            | ChatGPT: 87%            | ChatGPT: 85%    | 12.0%          |\n",
            "|               | DeepSeek: 80%           | DeepSeek: 82%           | DeepSeek: 75%   |                |\n",
            "+---------------+-------------------------+-------------------------+-----------------+----------------+\n",
            "| MATH          | ChatGPT: 70%            | ChatGPT: 80%            | ChatGPT: 60%    | 30.0%          |\n",
            "|               | DeepSeek: 75%           | DeepSeek: 75%           | DeepSeek: 50%   |                |\n",
            "+---------------+-------------------------+-------------------------+-----------------+----------------+\n",
            "| GPQA          | ChatGPT: 80%            | ChatGPT: 88%            | ChatGPT: 60%    | 38.0%          |\n",
            "|               | DeepSeek: 70%           | DeepSeek: 85%           | DeepSeek: 50%   |                |\n",
            "+---------------+-------------------------+-------------------------+-----------------+----------------+\n",
            "| MuSR          | ChatGPT: 80%            | ChatGPT: 86%            | ChatGPT: 85%    | 11.0%          |\n",
            "|               | DeepSeek: 75%           | DeepSeek: 78%           | DeepSeek: 80%   |                |\n",
            "+---------------+-------------------------+-------------------------+-----------------+----------------+\n",
            "| MMLU-Pro      | ChatGPT: N/D            | ChatGPT: 92%            | ChatGPT: 90%    | 12.0%          |\n",
            "|               | DeepSeek: N/D           | DeepSeek: 85%           | DeepSeek: 80%   |                |\n",
            "+---------------+-------------------------+-------------------------+-----------------+----------------+\n",
            "| CO2_Emissions | ChatGPT: 4.3g/consulta  | ChatGPT: 450g/resposta  | ChatGPT: N/D    | N/D            |\n",
            "|               | DeepSeek: 1.8g/consulta | DeepSeek: 600g/resposta | DeepSeek: N/D   |                |\n",
            "+---------------+-------------------------+-------------------------+-----------------+----------------+\n",
            "\n",
            "==========================================================================================\n",
            "\n",
            "Pressione Enter para continuar...\n",
            "\n",
            "======================================================================\n",
            "ü§ñ COMPARADOR AVAN√áADO DE LLMs: M√∫ltiplas Fontes de Dados\n",
            "======================================================================\n",
            "1. üìä Ver Tabela Comparativa (Fonte Atual)\n",
            "2. üåê Compara√ß√£o entre Todas as Fontes\n",
            "3. üìä Gr√°fico de Barras\n",
            "4. üå± An√°lise de Impacto Ambiental\n",
            "5. üí° Sistema de Recomenda√ß√£o\n",
            "6. üö™ Sair\n",
            "======================================================================\n",
            "Fonte atual: DeepSeek Source\n",
            "\n",
            "Escolha uma op√ß√£o (1-6): 6\n",
            "Obrigado por usar o comparador avan√ßado! üëã\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Instala√ß√£o de depend√™ncias necess√°rias (executar no terminal)\n",
        "    # pip install matplotlib numpy tabulate\n",
        "\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}